# Omnid Robot (PAGE BEING UPDATED)

## Video Demo

Conference Demo:

<iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/PgkkoWm-OUE?si=AgtToMl0cNfM7szw"
    frameborder="0"
    allow="autoplay; encrypted-media"
    allowfullscreen
>
</iframe>

## Description

Supported by the McCormick Summer Research Award at Northwestern University, my project, in collaboration with Professor Matthew Elwin, focused on enhancing the operational capabilities of the Center for Robotics and Biosystems' unique Omnid robots through the integration of advanced teleoperation features, live visualization, and the implementation of Lifecycle nodes.

At the core of this project was the development of a teleoperation feature, which introduced various control modes specifically tailored for the Omnid robots' unique mechanical and software design. This feature enables the execution of diverse experimental setups, laying the groundwork for comprehensive comparative analyses of human-multirobot and more conventional robot control methods. Our goal is to critically assess and elevate the efficiency and effectiveness of human-robot interaction within these contexts.

Parallel to the teleoperation advancements, I spearheaded the integration of a live visualization feature. This task required adept navigation and adaptation of the Omnid's intricate existing codebase that has been built on by several undergraduates, graduates, and research engineers before me. The successful implementation of live visualization now serves as a tool in the testing and diagnostics of the Omnid robots. It simplifies the debugging process and provides invaluable real-time insights into the robots' operational status, significantly improving testing methodologies and experimental accuracy.

Equally important was my work on engineering Lifecycle Node functionality. This enhancement marks a significant leap in the operational dynamics of the Omnid robots by enabling smooth transitioning between various control modes. The Lifecycle Nodes not only streamline the transition processes but also significantly enhance the human operator's experience by offering a more intuitive and responsive control interface. This integration is pivotal in our ongoing efforts to refine human-robot interaction, offering a seamless and more controlled operational environment that can adapt to diverse operational contexts with ease.

Together, these developments aim to create a more adaptable, efficient, and user-friendly platform for conducting robotic research and facilitating effective human-robot collaborations.

This work initiated the ROS Unified_Teleoperation project. More details are available in my portfolio.

***Date:*** July 2023 - September 2023

***Links:*** [Demonstration of NU's Omnid Robots](https://www.youtube.com/watch?v=SEuFfONryL0&t=5s)

## Gallery
### Videos (PAGE BEING UPDATED)

Float Teleop Mode:

<iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/FzNauYVdgLc?si=t54-GzDRyTJkSKZ6"
    frameborder="0"
    allow="autoplay; encrypted-media"
    allowfullscreen
>
</iframe>

Walk-the-Dog mode w/ Visualization:

<iframe
    width="560" height="315"
    src="https://www.youtube.com/embed/8pr5uS9haCk?si=CkHJKIMd7cCKyiOL"
    frameborder="0"
    allow="autoplay; encrypted-media"
    allowfullscreen
>
</iframe>


### Images

<img src="https://github.com/dkoh555/dkoh555.github.io/assets/107823507/39965570-dcb8-4c9b-9d9b-368141986ad2" height="300">

<img src="https://github.com/dkoh555/dkoh555.github.io/assets/107823507/66a42770-463c-48a3-a01f-6938baeb3fa9" height="300">

<img src="https://github.com/dkoh555/dkoh555.github.io/assets/107823507/74b8a6f1-8425-42e0-a6d4-a464df5a5f97" height="300">
